<!DOCTYPE html>
<html lang="en-ES">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Portfolio">
  <meta name="author" content="Maximiliano Benítez">
  <meta name="robots" content="noindex" />
  <title>Portfolio</title>
  <link href="css/styles.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Raleway&display=swap">
  <script src="https://kit.fontawesome.com/47dfdf5ad4.js" crossorigin="anonymous"></script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
</head>

<body>
  <nav class="c-nav_web">
    <a href="index.html">
      <h1>MACHINE LEARNING PORTFOLIO</h1>
    </a>
    <ul class="c-navigation__list">
      <li class="c-item">
        <a href="index.html">INICIO</a>
      </li>
      <li class="c-item is-active_web">
        <a href="blog.html">BLOG</a>
      </li>
      <li class="c-item">
        <a href="case_studies.html">CASOS DE ESTUDIO</a>
      </li>
      <li class="c-item">
        <a href="tools.html">HERRAMIENTAS</a>
      </li>
    </ul>
  </nav>

  <nav class="c-nav_mobile">
    <ul class="c-navigation__list">
      <li class="c-item">
        <a href="index.html">
          <i class="fa-solid fa-house fa-xl"></i></i>
          <span>INICIO</span>
        </a>
      </li>
      <li class="c-item is-active">
        <a href="blog.html">
          <i class="fa-solid fa-file fa-xl"></i>
          <span>BLOG</span>
        </a>
      </li>
      <li class="c-item">
        <a href="case_studies.html">
          <i class="fa-solid fa-book fa-xl"></i>
          <span>CASOS ESTUDIO</span>
        </a>
      </li>
      <li class="c-item">
        <a href="tools.html">
          <i class="fa-solid fa-wrench fa-xl"></i>
          <span>HERRAMIENTAS</span>
        </a>
      </li>
    </ul>
  </nav>

  <header class="underline">DESCENSO DE GRADIENTE</header>

  <main>
    <section class="c-container">
      <h2 class="c-content_header">DESCENSO DE GRADIENTE</h2>
      <div class="c-content">
        <p>En este blog, te presentaré un resumen capítulo 9 "Descenso de Gradiente" del libro "Master Machine
          Learning Algorithms", escrito por Jason Brownlee. Aquí podrás entender los conceptos fundamentales de esta
          técnica escencial de optimización de los modelos de machine learning.
        </p>

        <h3>Descenso de Gradiente</h3>
        <p>Es un algoritmo de optimización para encontrar los parámetros que minimizan una función de costo. Es
          especialmente útil cuando no se pueden calcular los parámetros de manera analítica y se requiere un enfoque de
          optimización.</p>
        <h5>Intuición para el Descenso de Gradiente</h5>
        <p>El objetivo es ir probando diferentes valores para los coeficientes, evaluar su costo y seleccionar nuevos
          coeficientes que tengan un costo ligeramente mejor (más bajo). Repetir este proceso varias veces conducirá a
          los coeficientes que resultan en el costo mínimo.</p>
        <h5>Procedimiento de Descenso de Gradiente</h5>
        <p>Se inicia con valores iniciales para los coeficientes.
          <br>
          $$coeficiente = 0.0$$
          <br>
          El costo de los coeficientes se evalúa al insertarlos en la función y calcular el costo.
          <br>
          $$costo = f(coeficiente)$$
          <br>
          Se calcula la derivada del costo. La derivada se refiere a la pendiente y necesitamos conocer la pendiente
          para saber la dirección (signo) en la que mover los valores de los coeficientes para obtener un costo más bajo
          en la siguiente iteración.
          <br>
          $$delta = derivada(costo)$$
          <br>
          Ahora podemos actualizar los valores de los coeficientes. Se debe especificar un parámetro de tasa de
          aprendizaje (alfa) que controle cuánto pueden cambiar los coeficientes en cada actualización.
          <br>
          $$coeficiente = coeficiente - (alfa \times delta)$$
          <br>
          Este proceso se repite hasta que el costo de los coeficientes (costo) sea 0.0 o no se puedan lograr más
          mejoras en el costo.
        </p>

        <h4>Descenso de Gradiente por Lotes</h4>
        <p>En algoritmos supervisados, se busca ajustar una función objetivo. La función de costo se calcula para todo
          el conjunto de entrenamiento, y los coeficientes se actualizan al final de cada lote de datos (lote se le
          llama a una iteración del algoritmo).
          Ejemplos comunes de algoritmos con coeficientes que se pueden optimizar utilizando el descenso de gradiente
          son la Regresión Lineal y la Regresión Logística.</p>
        <h4>Descenso de Gradiente Estocástico</h4>
        <p>En conjuntos de datos grandes, el descenso de gradiente puede ser lento. El descenso de gradiente estocástico
          actualiza los coeficientes para cada instancia de entrenamiento, siendo más rápido pero ruidoso.
          <br>
          $$prediction = \frac {1}{1+e^-(B0+B1\times X1+B2\times X2)}$$
        </p>

        <h4>Consejos para el Descenso del Gradiente</h4>
        <ul class="c-bulleted">
          <li>Graficar costo frente al tiempo</li>
          <li>Ajustar la tasa de aprendizaje</li>
          <li>Reescalar las entradas</li>
          <li>Considerar pocas pasadas</li>
          <li>Graficar el costo promedio</li>
        </ul>
      </div>
    </section>
  </main>

  <footer>
    <span>©2023 por Maximiliano Benítez. Creado en Github Pages</span>
  </footer>
</body>

</html>