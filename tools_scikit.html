<!DOCTYPE html>
<html lang="en-ES">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Portfolio">
  <meta name="author" content="Maximiliano Benítez">
  <meta name="robots" content="noindex" />
  <title>Portfolio</title>
  <link href="css/styles.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Raleway&display=swap">
  <script src="https://kit.fontawesome.com/47dfdf5ad4.js" crossorigin="anonymous"></script>
</head>

<body>
  <nav class="c-nav_web">
    <a href="index.html">
      <h1>MACHINE LEARNING PORTFOLIO</h1>
    </a>
    <ul class="c-navigation__list">
      <li id="li-home" class="c-item">
        <a href="index.html">INICIO</a>
      </li>
      <li id="li-blog" class="c-item">
        <a href="blog.html">BLOG</a>
      </li>
      <li id="li-case__studies" class="c-item">
        <a href="case_studies.html">CASOS DE ESTUDIO</a>
      </li>
      <li id="li-tools" class="c-item is-active_web">
        <a href="tools.html">HERRAMIENTAS</a>
      </li>
    </ul>
  </nav>

  <nav class="c-nav_mobile">
    <ul class="c-navigation__list">
      <li id="li-home" class="c-item">
        <a href="index.html">
          <i class="fa-solid fa-house fa-xl"></i></i>
          <span>INICIO</span>
        </a>
      </li>
      <li id="li-blog" class="c-item">
        <a href="blog.html">
          <i class="fa-regular fa-file fa-xl"></i>
          <span>BLOG</span>
        </a>
      </li>
      <li id="li-case__studies" class="c-item">
        <a href="case_studies.html">
          <i class="fa-solid fa-book fa-xl"></i>
          <span>CASOS ESTUDIO</span>
        </a>
      </li>
      <li id="li-tools" class="c-item is-active">
        <a href="tools.html">
          <i class="fa-solid fa-wrench fa-xl"></i>
          <span>HERRAMIENTAS</span>
        </a>
      </li>
    </ul>
  </nav>

  <header class="underline">SCIKIT - LEARN</header>

  <main>
    <section class="c-container">
      <h2 class="c-content_header">SCIKIT - LEARN</h2>
      <div class="c-content">
        <p>En esta entrada, profundizaré en una de las librerías esenciales en machine learning.
          Podrás ver algunas de sus numerosas funciones y los parámetros que cada una ofrece.
        </p>

        <h4>Preprocesamiento de datos</h4>
        <ul class="c-code_list">
          <li><code>sklearn.preprocessing.StandardScaler()</code>: Estandariza las características escalando a una media
            cero y una desviación estándar de uno.</li>
          <li><code>sklearn.preprocessing.MinMaxScaler()</code>: Escala características a un rango específico (por
            defecto, [0, 1]).
            <ul class="c-sublist">
              <li><strong>feature_range</strong>: Especifica el rango al que se escalan las características (por defecto es
                [0, 1]).</li>
            </ul>
          </li>
          <li><code>sklearn.preprocessing.LabelEncoder()</code>: Codifica etiquetas de clases en valores numéricos.</li>
          <li><code>sklearn.preprocessing.OneHotEncoder()</code>: Codifica características categóricas en vectores
            binarios (one-hot encoding).
            <ul class="c-sublist">
              <li><strong>categories</strong>: Lista de listas que especifica las categorías para cada característica (por
                defecto es 'auto').</li>
            </ul>
          </li>
          <li><code>sklearn.preprocessing.Imputer()</code>: Rellena valores faltantes en los datos.
            <ul class="c-sublist">
              <li><strong>missing_values</strong>: Valor o lista de valores que se consideran faltantes (por defecto es
                'NaN').</li>
              <li><strong>strategy</strong>: Estrategia para llenar valores faltantes (por defecto es 'mean').</li>
            </ul>
          </li>
        </ul>

        <h4>Selección de características</h4>
        <ul class="c-code_list">
          <li><code>sklearn.feature_selection.SelectKBest()</code>: Selecciona las mejores características basadas en
            pruebas estadísticas.
            <ul class="c-sublist">
              <li><strong>score_func</strong>: Función de puntuación para evaluar características (por defecto es
                f_classif).</li>
              <li><strong>k</strong>: Número de características a seleccionar.</li>
            </ul>
          </li>
          <li><code>sklearn.feature_selection.RFE()</code>: Elimina recursivamente las características menos
            importantes.
            <ul class="c-sublist">
              <li><strong>estimator</strong>: Estimador que se utiliza para calcular la importancia de las características.
              </li>
              <li><strong>n_features_to_select</strong>: Número de características a seleccionar (por defecto es None).</li>
            </ul>
          </li>
          <li><code>sklearn.feature_selection.VarianceThreshold()</code>: Elimina características con varianza por
            debajo de un umbral dado.
            <ul class="c-sublist">
              <li><strong>threshold</strong>: Umbral de varianza por debajo del cual se eliminarán las características (por
                defecto es 0).</li>
            </ul>
          </li>
        </ul>

        <h4>Modelos de aprendizaje automático</h4>
        <ul class="c-code_list">
          <li><code>fit()</code>: La función se utiliza para entrenar un modelo utilizando datos de entrenamiento.
            <ul class="c-sublist">
              <li><strong>X</strong>: Matriz de características de entrenamiento.</li>
              <li><strong>Y</strong>: Vector de etiquetas de clase de las muestras de entrenamiento.</li>
              <li><strong>solver</strong>: Algoritmo de optimización.</li>
            </ul>
          </li>
          <li><code>predict()</code>: La función se utiliza para realizar predicciones utilizando un modelo entrenado.
            <ul class="c-sublist">
              <li><strong>X</strong>: Matriz de características de prueba para la cual se desean realizar las predicciones.
              </li>
            </ul>
          </li>
        </ul>

        <h5>Clasificación</h5>
        <ul class="c-code_list">
          <li><code>sklearn.linear_model.LogisticRegression()</code>: Regresión logística para clasificación binaria o
            multinomial.
            <ul class="c-sublist">
              <li><strong>penalty</strong>: Tipo de regularización (por defecto es 'l2').</li>
              <li><strong>C</strong>: Inverso de la fuerza de regularización (por defecto es 1.0).</li>
              <li><strong>solver</strong>: Algoritmo de optimización (por defecto es 'lbfgs').</li>
              <li><strong>max_iter</strong>: Número máximo de iteraciones (por defecto es 100).</li>
            </ul>
          </li>
          <li><code>sklearn.svm.SVC()</code>: Máquinas de soporte vectorial para clasificación.
            <ul class="c-sublist">
              <li><strong>C</strong>: Parámetro de regularización.</li>
              <li><strong>kernel</strong>: Función de kernel (por defecto es 'rbf').</li>
              <li><strong>gamma</strong>: Coeficiente del kernel (por defecto es 'scale').</li>
              <li><strong>degree</strong>: Grado del kernel polinómico (si se utiliza kernel polinómico).</li>
            </ul>
          </li>
          <li><code>sklearn.ensemble.RandomForestClassifier()</code>: Clasificador de bosques aleatorios.
            <ul class="c-sublist">
              <li><strong>n_estimators</strong>: Número de árboles en el bosque (por defecto es 100).</li>
              <li><strong>max_depth</strong>: Profundidad máxima de los árboles (por defecto es None).</li>
              <li><strong>min_samples_split</strong>: Número mínimo de muestras requeridas para dividir un nodo (por defecto
                es 2).</li>
            </ul>
          </li>
          <li><code>sklearn.naive_bayes.GaussianNB()</code>: Clasificador Naïve Bayes Gaussiano.</li>
          <li><code>sklearn.neighbors.KNeighborsClassifier()</code>: Clasificador k-Nearest Neighbors (k-NN).
            <ul class="c-sublist">
              <li><strong>n_neighbors</strong>: Número de vecinos a considerar (por defecto es 5).</li>
              <li><strong>weights</strong>: Función de peso (por defecto es 'uniform').</li>
              <li><strong>algorithm</strong>: Algoritmo utilizado para calcular vecinos (por defecto es 'auto').</li>
            </ul>
          </li>
          <li><code>sklearn.discriminant_analysis.LinearDiscriminantAnalysis()</code>: Análisis discriminante lineal
            (LDA) para clasificación.
            <ul class="c-sublist">
              <li><strong>solver</strong>: Algoritmo de solución (por defecto es 'svd').</li>
              <li><strong>shrinkage</strong>: Método de reducción de dimensionalidad (por defecto es None).</li>
            </ul>
          </li>
        </ul>

        <h5>Regresión</h5>
        <ul class="c-code_list">
          <li><code>sklearn.linear_model.LinearRegression()</code>: Regresión lineal.</li>
          <li><code>sklearn.tree.DecisionTreeRegressor()</code>: Regresor basado en árboles de decisión.
            <ul class="c-sublist">
              <li><strong>max_depth</strong>: Profundidad máxima del árbol (por defecto es None).</li>
              <li><strong>min_samples_split</strong>: Número mínimo de muestras requeridas para dividir un nodo (por defecto
                es 2).</li>
            </ul>
          </li>
          <li><code>sklearn.ensemble.RandomForestRegressor()</code>: Regresor de bosques aleatorios.
            <ul class="c-sublist">
              <li><strong>n_estimators</strong>: Número de árboles en el bosque (por defecto es 100).</li>
              <li><strong>max_depth</strong>: Profundidad máxima de los árboles (por defecto es None).</li>
              <li><strong>min_samples_split</strong>: Número mínimo de muestras requeridas para dividir un nodo (por defecto
                es 2).</li>
            </ul>
          </li>
          <li><code>sklearn.neighbors.KNeighborsRegressor()</code>: Regresor k-Nearest Neighbors (k-NN).
            <ul class="c-sublist">
              <li><strong>n_neighbors</strong>: Número de vecinos a considerar (por defecto es 5).</li>
              <li><strong>weights</strong>: Función de peso (por defecto es 'uniform').</li>
              <li><strong>algorithm</strong>: Algoritmo utilizado para calcular vecinos (por defecto es 'auto').</li>
            </ul>
          </li>
        </ul>

        <h5>Clustering</h5>
        <ul class="c-code_list">
          <li><code>sklearn.cluster.KMeans()</code>: Realiza el algoritmo de K-Means para agrupación.
            <ul class="c-sublist">
              <li><strong>n_clusters</strong>: Número de clusters (grupos) a crear.</li>
              <li><strong>init</strong>: Método de inicialización de centroides, como 'k-means++', 'random', o proporcionar
                una matriz de centroides iniciales.</li>
              <li><strong>n_init</strong>: Número de veces que se ejecutará el algoritmo con diferentes centroides
                iniciales.</li>
              <li><strong>max_iter</strong>: Número máximo de iteraciones para converger a una solución.</li>
              <li><strong>tol</strong>: Tolerancia para la convergencia del algoritmo.</li>
              <li><strong>algorithm</strong>: Algoritmo para calcular K-Means, como 'auto', 'full', 'elkan'.</li>
            </ul>
          </li>
        </ul>

        <h4>Evaluación de modelos</h4>
        <ul class="c-code_list">
          <li><code>sklearn.model_selection.train_test_split()</code>: Divide los datos en conjuntos de entrenamiento y
            prueba.
            <ul class="c-sublist">
              <li><strong>arrays</strong>: Los datos a dividir (características y etiquetas).</li>
              <li><strong>test_size</strong>: Tamaño del conjunto de prueba (fracción o número).</li>
              <li><strong>train_size</strong>: Tamaño del conjunto de entrenamiento (fracción o se calcula automáticamente).
              </li>
              <li><strong>random_state</strong>: Semilla aleatoria.</li>
              <li><strong>shuffle</strong>: Reorganiza los datos antes de la división (Verdadero/Falso).</li>
              <li><strong>stratify</strong>: Mantiene la proporción de clases en la división (Verdadero/Falso).</li>
            </ul>
          </li>
          <li><code>sklearn.metrics.accuracy_score()</code>: Calcula la precisión de las predicciones.
            <ul class="c-sublist">
              <li><strong>y_true</strong>: Etiquetas verdaderas.</li>
              <li><strong>y_pred</strong>: Etiquetas predichas.</li>
            </ul>
          </li>
          <li><code>sklearn.metrics.confusion_matrix()</code>: Calcula la matriz de confusión.
            <ul class="c-sublist">
              <li><strong>y_true</strong>: Etiquetas verdaderas.</li>
              <li><strong>y_pred</strong>: Etiquetas predichas.</li>
              <li><strong>labels</strong>: Etiquetas de clases (opcional).</li>
            </ul>
          </li>
          <li><code>sklearn.metrics.mean_squared_error()</code>: Calcula el error cuadrático medio.
            <ul class="c-sublist">
              <li><strong>y_true</strong>: Valores verdaderos.</li>
              <li><strong>y_pred</strong>: Valores predichos.</li>
            </ul>
          </li>
          <li><code>sklearn.metrics.classification_report()</code>: Genera un informe de clasificación detallado.
            <ul class="c-sublist">
              <li><strong>y_true</strong>: Etiquetas verdaderas.</li>
              <li><strong>y_pred</strong>: Etiquetas predichas.</li>
              <li><strong>target_names</strong>: Nombres de las etiquetas de clases (opcional).</li>
            </ul>
          </li>
          <li><code>sklearn.metrics.roc_curve()</code>: Calcula la curva ROC y el área bajo la curva ROC (AUC).
            <ul class="c-sublist">
              <li><strong>y_true</strong>: Etiquetas verdaderas.</li>
              <li><strong>y_score</strong>: Puntajes o probabilidades de clase (en lugar de etiquetas predichas).</li>
            </ul>
          </li>
        </ul>

        <h4>Validación cruzada</h4>
        <ul class="c-code_list">
          <li><code>sklearn.model_selection.cross_val_score()</code>: Realiza validación cruzada para estimar el
            rendimiento del modelo.
            <ul class="c-sublist">
              <li><strong>estimator</strong>: Estimador para evaluar.</li>
              <li><strong>X</strong>: Datos de entrenamiento.</li>
              <li><strong>y</strong>: Etiquetas de entrenamiento.</li>
              <li><strong>cv</strong>: Esquema de validación cruzada (por defecto es 5-fold).</li>
              <li><strong>scoring</strong>: Métrica de evaluación a utilizar (por defecto es None).</li>
            </ul>
          </li>
          <li><code>sklearn.model_selection.GridSearchCV()</code>: Realiza una búsqueda de hiperparámetros a través de
            validación cruzada.
            <ul class="c-sublist">
              <li><strong>estimator</strong>: Estimador para ajustar.</li>
              <li><strong>param_grid</strong>: Diccionario de hiperparámetros a buscar.</li>
              <li><strong>cv</strong>: Esquema de validación cruzada (por defecto es 5-fold).</li>
              <li><strong>scoring</strong>: Métrica de evaluación a utilizar (por defecto es None).</li>
            </ul>
          </li>
        </ul>

        <h4>Reducción de dimensionalidad</h4>
        <ul class="c-code_list">
          <li><code>sklearn.decomposition.PCA()</code>: Realiza el análisis de componentes principales (PCA) para
            reducción de dimensionalidad.
            <ul class="c-sublist">
              <li><strong>n_components</strong>: Número de componentes principales a retener.</li>
            </ul>
          </li>
        </ul>
      </div>
    </section>
  </main>

  <footer>
    <span>©2023 por Maximiliano Benítez. Creado en Github Pages</span>
  </footer>
</body>

</html>